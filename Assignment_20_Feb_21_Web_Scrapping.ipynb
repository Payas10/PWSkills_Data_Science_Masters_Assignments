{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce769183-f9f9-46f9-92cd-11aa637800ae",
   "metadata": {},
   "source": [
    "# Assignment 20 - Feb 21' 23 - Web Scrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddd0d7f-62c9-41c3-ad47-b64575d82a1a",
   "metadata": {},
   "source": [
    "### 1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7f6be1-857e-485b-86ea-addfe7b28b25",
   "metadata": {},
   "source": [
    "#### WHAT?\n",
    "Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications.\n",
    "\n",
    "#### WHY\n",
    "Web scrapping is used to get large amounts of information from a website as quickly as possible and such large amounts of data extracyed from a website can be further used to train a Machine Learning algorithm. \n",
    "\n",
    "#### AREAS?\n",
    "1. Price Monitoring\n",
    "> Web Scraping can be used by companies to scrap the product data for their products and competing products as well to see how it impacts their pricing strategies. Companies can use this data to fix the optimal pricing for their products so that they can obtain maximum revenue.\n",
    "\n",
    "2. Market Research\n",
    "> Web scraping can be used for market research by companies. High-quality web scraped data obtained in large volumes can be very helpful for companies in analyzing consumer trends and understanding which direction the company should move in the future. \n",
    "\n",
    "3. News Monitoring\n",
    "> Web scraping news sites can provide detailed reports on the current news to a company. This is even more essential for companies that are frequently in the news or that depend on daily news for their day-to-day functioning. After all, news reports can make or break a company in a single day!\n",
    "\n",
    "4. Sentiment Analysis\n",
    "> If companies want to understand the general sentiment for their products among their consumers, then Sentiment Analysis is a must. Companies can use web scraping to collect data from social media websites such as Facebook and Twitter as to what the general sentiment about their products is. This will help them in creating products that people desire and moving ahead of their competition.\n",
    "\n",
    "5. Email Marketing\n",
    "> Companies can also use Web scraping for email marketing. They can collect Email ID’s from various sites using web scraping and then send bulk promotional and marketing Emails to all the people owning these Email ID’s.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d086f7a-bb53-4309-ae89-60455b3bc9eb",
   "metadata": {},
   "source": [
    "### 2.  What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420e2d10-9fd9-4e16-b888-5b7e72f0c8b2",
   "metadata": {},
   "source": [
    "1. **Manual scraping (Copy-pasting)** - The manual human examination and copy-pasting method may sometimes prove irreplaceable. At times, this technique may be the only practical method to use especially when websites are setup with barriers and machine automation cannot be enabled.\n",
    "2. **DOM Parsing** - In order to dynamically modify or inspect a web page, client-side scripts parse the contents of the web page into a DOM tree. By embedding a program into the web browser, you can then retrieve the information from the tree.\n",
    "3. **HTTP Programming** - Using socket programming, posting HTTP requests can help one retrieve dynamic as well as static web page information.\n",
    "4. **Recognizing Semantic Annotation** - Most web pages have semantic annotations/markup or metadata that can be easily retrieved. This could be a simple case of DOM parsing if the metadata is just embedded in the web page. Web scrapers can also use the annotations located in the semantic layer of the web page before actually scraping it.\n",
    "5. **Text Grepping** - Using Python programming languages or Perl, one can use the UNIX grep command to extract valuable data and information from web pages.\n",
    "6. **Web scraping Software** - If you do not want to manually use web-scraping codes, you can make use of a software that can do the web scraping for you. It can automatically retrieve the information off the web page, convert it into recognizable information, and store it in a local database. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f944fd3-307e-4f6e-b1f4-a18e5fc421ec",
   "metadata": {},
   "source": [
    "### 3.  What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18771799-1f9f-4c2a-bb01-0632f2691b09",
   "metadata": {},
   "source": [
    "#### WHAT?\n",
    "* BeautifulSoup is a Python package used for parsing HTML and XML documents, it creates a parse tree for parsed paged which can be used for web scraping, it pulls data from HTML and XML files and works with your favorite parser to provide the idiomatic way of navigating, searching, and modifying the parse tree.\n",
    "* This module does not come built-in with Python. To install this type the below command in the terminal.\n",
    "> pip install bs4\n",
    "\n",
    "#### WHY?\n",
    "* Beautiful Soup is a Python library for getting data out of HTML, XML, and other markup languages. Say you’ve found some webpages that display data relevant to your research, such as date or address information, but that do not provide any way of downloading the data directly. \n",
    "* Beautiful Soup helps you pull particular content from a webpage, remove the HTML markup, and save the information. It is a tool for web scraping that helps you clean up and parse the documents you have pulled down from the web."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8504465a-5fb0-4f33-9770-3d5500e799ce",
   "metadata": {},
   "source": [
    "### 4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5de384-6ab3-42de-be84-3961c5bd840c",
   "metadata": {},
   "source": [
    "* Flask is a lightweight framework to build websites. We are using this to parse our collected data and display it as HTML.\n",
    "* With flask we created a simple server that will take our index.html from the templates folder and serve or render it on a local server —  localhost://5000\n",
    "* The requests module fron Flask allows us to send http requests to the website we want to scrape. In this project we send a GET request to productLink and convert the HTML to plain text and store that in the prodRes (source) variable.\n",
    "* Lastly, flask is re-rendering our received data the way we want by taking results.html from the templates folder and rendering back it on a local server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f605ed-aae5-4432-bbe0-5293c53bba50",
   "metadata": {},
   "source": [
    "### 5. Write the names of AWS services used in this project. Also, explain the use of each service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebb8a00-281e-4d53-bca4-f852df7804af",
   "metadata": {},
   "source": [
    "* Two AWS services are used in this project.\n",
    "> 1. AWS Code Pipeline\n",
    "> 2. AWS Elastic BeanStalk\n",
    "\n",
    "* AWS Code Pipeline\n",
    "> * AWS CodePipeline is a continuous delivery service which can use to model, visualize, and automate the steps required to release software. We can quickly model and configure the different stages of a software release process. CodePipeline automates the steps required to release software changes continuously.\n",
    "> * We can easily integrate AWS CodePipeline with third-party services such as GitHub or with your own custom plugin.\n",
    "> * In this project we first deploy or push our code from lab to github and then integrated the AWS CodePipeline to Github to deploy our project to BeanStalk.\n",
    "\n",
    "* AWS Elastic BeanStalk\n",
    "> * Unlike EC-2 which is Infrastructure as a service, Elastic beanstalk is a Platform As A service (PAAS) as it allows users to directly us a pre-configured server for their application.\n",
    "> * AWS Elastic Beanstalk is an AWS managed service for web applications. Elastic beanstalk is a pre-configured EC2 server that can directly take up your application code and environment configurations and use it to automatically provision and deploy the required resources within AWS to run the web application. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e6a25a-d776-41cd-a54c-8e93384bbd0d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
